{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Burt (2004) Structural Holes Dataset\\n",
    "\\n",
    "This notebook provides an interactive EDA for the synthetic companion dataset based on:\\n",
    "\\n",
    "**Burt, Ronald S. 2004. \\"Structural Holes and Good Ideas.\\" _American Journal of Sociology_ 110(2):349-399.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\\n",
    "import numpy as np\\n",
    "import matplotlib.pyplot as plt\\n",
    "import seaborn as sns\\n",
    "import networkx as nx\\n",
    "from pathlib import Path\\n",
    "import warnings\\n",
    "\\n",
    "warnings.filterwarnings('ignore')\\n",
    "\\n",
    "# Set style\\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\\n",
    "sns.set_palette(\\"husl\\")\\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\\n",
    "plt.rcParams['font.size'] = 10\\n",
    "\\n",
    "print(\\"✓ Libraries loaded successfully\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\\n",
    "nodes = pd.read_csv('nodes.csv')\\n",
    "edges = pd.read_csv('edges.csv')\\n",
    "\\n",
    "print(f\\"Nodes: {nodes.shape[0]} employees × {nodes.shape[1]} variables\\")\\n",
    "print(f\\"Edges: {edges.shape[0]} relationships\\")\\n",
    "\\n",
    "# Display first few rows\\n",
    "display(nodes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\\n",
    "print(\\"Numeric Variables:\\")\\n",
    "display(nodes.describe())\\n",
    "\\n",
    "print(\\"\\\\nMissing Values:\\")\\n",
    "missing = nodes.isnull().sum()\\n",
    "missing_pct = (missing / len(nodes)) * 100\\n",
    "missing_df = pd.DataFrame({\\n",
    "    'Missing Count': missing[missing > 0],\\n",
    "    'Missing %': missing_pct[missing > 0]\\n",
    "})\\n",
    "if len(missing_df) > 0:\\n",
    "    display(missing_df.sort_values('Missing Count', ascending=False))\\n",
    "else:\\n",
    "    print(\\"No missing values found.\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network\\n",
    "G = nx.from_pandas_edgelist(edges, 'source', 'target', edge_attr='weight')\\n",
    "\\n",
    "print(f\\"Network Properties:\\")\\n",
    "print(f\\"  Nodes: {G.number_of_nodes()}\\")\\n",
    "print(f\\"  Edges: {G.number_of_edges()}\\")\\n",
    "print(f\\"  Density: {nx.density(G):.4f}\\")\\n",
    "print(f\\"  Is Connected: {nx.is_connected(G)}\\")\\n",
    "\\n",
    "# Connected components\\n",
    "components = list(nx.connected_components(G))\\n",
    "print(f\\"  Number of Components: {len(components)}\\")\\n",
    "print(f\\"  Largest Component Size: {len(max(components, key=len))}\\")\\n",
    "\\n",
    "# Degree statistics\\n",
    "degrees = dict(G.degree())\\n",
    "degree_values = list(degrees.values())\\n",
    "print(f\\"\\\\nDegree Statistics:\\")\\n",
    "print(f\\"  Mean: {np.mean(degree_values):.2f}\\")\\n",
    "print(f\\"  Median: {np.median(degree_values):.0f}\\")\\n",
    "print(f\\"  Max: {np.max(degree_values)}\\")\\n",
    "print(f\\"  Min: {np.min(degree_values)}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic distributions\\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\\n",
    "fig.suptitle('Demographic Distributions', fontsize=16, fontweight='bold')\\n",
    "\\n",
    "# Age\\n",
    "axes[0, 0].hist(nodes['age'], bins=20, edgecolor='black', alpha=0.7)\\n",
    "axes[0, 0].set_xlabel('Age (years)')\\n",
    "axes[0, 0].set_ylabel('Frequency')\\n",
    "axes[0, 0].set_title('Age Distribution')\\n",
    "axes[0, 0].axvline(nodes['age'].mean(), color='red', linestyle='--', label=f\\"Mean: {nodes['age'].mean():.1f}\\")\\n",
    "axes[0, 0].legend()\\n",
    "\\n",
    "# Education\\n",
    "edu_counts = nodes['education'].value_counts()\\n",
    "axes[0, 1].bar(range(len(edu_counts)), edu_counts.values, edgecolor='black')\\n",
    "axes[0, 1].set_xticks(range(len(edu_counts)))\\n",
    "axes[0, 1].set_xticklabels(edu_counts.index, rotation=45, ha='right')\\n",
    "axes[0, 1].set_ylabel('Count')\\n",
    "axes[0, 1].set_title('Education')\\n",
    "\\n",
    "# Rank\\n",
    "rank_counts = nodes['rank'].value_counts().sort_index()\\n",
    "axes[0, 2].bar(range(len(rank_counts)), rank_counts.values, edgecolor='black')\\n",
    "axes[0, 2].set_xticks(range(len(rank_counts)))\\n",
    "axes[0, 2].set_xticklabels(rank_counts.index, rotation=45, ha='right')\\n",
    "axes[0, 2].set_ylabel('Count')\\n",
    "axes[0, 2].set_title('Job Rank')\\n",
    "\\n",
    "# Role\\n",
    "role_counts = nodes['role'].value_counts()\\n",
    "axes[1, 0].bar(range(len(role_counts)), role_counts.values, edgecolor='black')\\n",
    "axes[1, 0].set_xticks(range(len(role_counts)))\\n",
    "axes[1, 0].set_xticklabels(role_counts.index)\\n",
    "axes[1, 0].set_ylabel('Count')\\n",
    "axes[1, 0].set_title('Role')\\n",
    "\\n",
    "# Business Unit\\n",
    "bu_counts = nodes['business_unit'].value_counts()\\n",
    "axes[1, 1].bar(range(len(bu_counts)), bu_counts.values, edgecolor='black')\\n",
    "axes[1, 1].set_xticks(range(len(bu_counts)))\\n",
    "axes[1, 1].set_xticklabels(bu_counts.index, rotation=45, ha='right')\\n",
    "axes[1, 1].set_ylabel('Count')\\n",
    "axes[1, 1].set_title('Business Unit')\\n",
    "\\n",
    "# Isolate\\n",
    "isolate_counts = nodes['isolate'].value_counts()\\n",
    "colors = ['#2ecc71' if x == False else '#e74c3c' for x in isolate_counts.index]\\n",
    "axes[1, 2].bar(range(len(isolate_counts)), isolate_counts.values, color=colors, edgecolor='black')\\n",
    "axes[1, 2].set_xticks(range(len(isolate_counts)))\\n",
    "axes[1, 2].set_xticklabels(['Connected', 'Isolate'])\\n",
    "axes[1, 2].set_ylabel('Count')\\n",
    "axes[1, 2].set_title('Social Isolate Status')\\n",
    "\\n",
    "plt.tight_layout()\\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Network Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network position metrics (non-isolates)\\n",
    "non_isolates = nodes[nodes['isolate'] == False]\\n",
    "\\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\\n",
    "fig.suptitle('Network Position Metrics', fontsize=16, fontweight='bold')\\n",
    "\\n",
    "# Degree\\n",
    "axes[0, 0].hist(non_isolates['degree'], bins=30, edgecolor='black', alpha=0.7)\\n",
    "axes[0, 0].set_xlabel('Degree')\\n",
    "axes[0, 0].set_ylabel('Frequency')\\n",
    "axes[0, 0].set_title('Degree Distribution')\\n",
    "axes[0, 0].axvline(non_isolates['degree'].mean(), color='red', linestyle='--')\\n",
    "\\n",
    "# Weighted Degree\\n",
    "axes[0, 1].hist(non_isolates['weighted_degree'], bins=30, edgecolor='black', alpha=0.7, color='orange')\\n",
    "axes[0, 1].set_xlabel('Weighted Degree')\\n",
    "axes[0, 1].set_ylabel('Frequency')\\n",
    "axes[0, 1].set_title('Weighted Degree')\\n",
    "axes[0, 1].axvline(non_isolates['weighted_degree'].mean(), color='red', linestyle='--')\\n",
    "\\n",
    "# Log Constraint\\n",
    "axes[0, 2].hist(non_isolates['log_constraint'], bins=30, edgecolor='black', alpha=0.7, color='green')\\n",
    "axes[0, 2].set_xlabel('Log Constraint')\\n",
    "axes[0, 2].set_ylabel('Frequency')\\n",
    "axes[0, 2].set_title('Log Constraint')\\n",
    "axes[0, 2].axvline(non_isolates['log_constraint'].mean(), color='red', linestyle='--')\\n",
    "\\n",
    "# Betweenness\\n",
    "axes[1, 0].hist(non_isolates['betweenness'], bins=30, edgecolor='black', alpha=0.7, color='purple')\\n",
    "axes[1, 0].set_xlabel('Betweenness')\\n",
    "axes[1, 0].set_ylabel('Frequency')\\n",
    "axes[1, 0].set_title('Betweenness Centrality')\\n",
    "axes[1, 0].axvline(non_isolates['betweenness'].mean(), color='red', linestyle='--')\\n",
    "\\n",
    "# Clustering\\n",
    "axes[1, 1].hist(non_isolates['clustering'], bins=30, edgecolor='black', alpha=0.7, color='brown')\\n",
    "axes[1, 1].set_xlabel('Clustering')\\n",
    "axes[1, 1].set_ylabel('Frequency')\\n",
    "axes[1, 1].set_title('Clustering Coefficient')\\n",
    "axes[1, 1].axvline(non_isolates['clustering'].mean(), color='red', linestyle='--')\\n",
    "\\n",
    "# Degree vs Constraint\\n",
    "axes[1, 2].scatter(non_isolates['degree'], non_isolates['log_constraint'], alpha=0.5, s=10)\\n",
    "axes[1, 2].set_xlabel('Degree')\\n",
    "axes[1, 2].set_ylabel('Log Constraint')\\n",
    "corr = non_isolates[['degree', 'log_constraint']].corr().iloc[0, 1]\\n",
    "axes[1, 2].set_title(f'Degree vs Constraint (r={corr:.3f})')\\n",
    "\\n",
    "plt.tight_layout()\\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Structural Holes and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key theoretical relationships\\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n",
    "fig.suptitle('Structural Holes Theory: Key Relationships', fontsize=16, fontweight='bold')\\n",
    "\\n",
    "# Constraint vs Salary\\n",
    "valid_mask = nodes['log_constraint'].notna() & nodes['salary_resid'].notna()\\n",
    "axes[0].scatter(nodes.loc[valid_mask, 'log_constraint'], \\n",
    "                nodes.loc[valid_mask, 'salary_resid'], alpha=0.3, s=20)\\n",
    "axes[0].set_xlabel('Log Constraint (Higher = More Closed Network)')\\n",
    "axes[0].set_ylabel('Salary Residual (Standardized)')\\n",
    "axes[0].set_title('Network Constraint vs Salary Performance')\\n",
    "axes[0].axhline(0, color='gray', linestyle='--', alpha=0.5)\\n",
    "\\n",
    "# Add trend line\\n",
    "z = np.polyfit(nodes.loc[valid_mask, 'log_constraint'], \\n",
    "               nodes.loc[valid_mask, 'salary_resid'], 1)\\n",
    "p = np.poly1d(z)\\n",
    "x_line = np.linspace(nodes['log_constraint'].min(), nodes['log_constraint'].max(), 100)\\n",
    "axes[0].plot(x_line, p(x_line), \\"r--\\", alpha=0.8, linewidth=2)\\n",
    "corr = nodes[valid_mask][['log_constraint', 'salary_resid']].corr().iloc[0, 1]\\n",
    "axes[0].text(0.05, 0.95, f'r = {corr:.3f}', transform=axes[0].transAxes,\\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\\n",
    "\\n",
    "# Constraint vs Idea Value\\n",
    "ideas = nodes[nodes['idea_expressed'] == True]\\n",
    "valid_mask = ideas['log_constraint'].notna() & ideas['idea_value'].notna()\\n",
    "axes[1].scatter(ideas.loc[valid_mask, 'log_constraint'], \\n",
    "                ideas.loc[valid_mask, 'idea_value'], alpha=0.6, s=30)\\n",
    "axes[1].set_xlabel('Log Constraint (Higher = More Closed Network)')\\n",
    "axes[1].set_ylabel('Idea Value (1-5)')\\n",
    "axes[1].set_title('Network Constraint vs Idea Quality')\\n",
    "\\n",
    "# Add trend line\\n",
    "z = np.polyfit(ideas.loc[valid_mask, 'log_constraint'], \\n",
    "               ideas.loc[valid_mask, 'idea_value'], 1)\\n",
    "p = np.poly1d(z)\\n",
    "x_line = np.linspace(ideas['log_constraint'].min(), ideas['log_constraint'].max(), 100)\\n",
    "axes[1].plot(x_line, p(x_line), \\"r--\\", alpha=0.8, linewidth=2)\\n",
    "corr = ideas[valid_mask][['log_constraint', 'idea_value']].corr().iloc[0, 1]\\n",
    "axes[1].text(0.05, 0.95, f'r = {corr:.3f}', transform=axes[1].transAxes,\\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\\n",
    "\\n",
    "plt.tight_layout()\\n",
    "plt.show()\\n",
    "\\n",
    "print(\\"\\\\nKey Finding: Managers with networks spanning structural holes (low constraint)\\")\\n",
    "print(\\"  → Receive higher salaries (weak effect overall, stronger at senior ranks)\\")\\n",
    "print(\\"  → Generate more valuable ideas (strong effect, r = {:.3f})\\".format(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\\n",
    "corr_vars = ['age', 'degree', 'weighted_degree', 'log_constraint', 'betweenness', \\n",
    "             'clustering', 'salary_resid', 'idea_value']\\n",
    "corr_data = nodes[corr_vars].corr()\\n",
    "\\n",
    "plt.figure(figsize=(10, 8))\\n",
    "sns.heatmap(corr_data, annot=True, fmt='.2f', cmap='coolwarm', center=0,\\n",
    "            square=True, linewidths=1, cbar_kws={\\"shrink\\": 0.8})\\n",
    "plt.title('Correlation Matrix: Network Metrics and Outcomes', fontsize=14, fontweight='bold')\\n",
    "plt.tight_layout()\\n",
    "plt.show()\\n",
    "\\n",
    "# Print key correlations\\n",
    "print(\\"\\\\nKey Theoretical Correlations:\\")\\n",
    "print(f\\"  degree ↔ log_constraint: {corr_data.loc['degree', 'log_constraint']:.3f}\\")\\n",
    "print(f\\"  log_constraint ↔ idea_value: {corr_data.loc['log_constraint', 'idea_value']:.3f}\\")\\n",
    "print(f\\"  degree ↔ idea_value: {corr_data.loc['degree', 'idea_value']:.3f}\\")\\n",
    "print(f\\"  log_constraint ↔ salary_resid: {corr_data.loc['log_constraint', 'salary_resid']:.3f}\\")\\n",
    "print(f\\"  betweenness ↔ log_constraint: {corr_data.loc['betweenness', 'log_constraint']:.3f}\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\\"="*80)\\n",
    "print(\\"SUMMARY STATISTICS\\")\\n",
    "print(\\"="*80)\\n",
    "\\n",
    "print(f\\"\\\\nDataset Overview:\\")\\n",
    "print(f\\"  Total Employees: {len(nodes)}\\")\\n",
    "print(f\\"  Total Relationships: {len(edges)}\\")\\n",
    "print(f\\"  Social Isolates: {nodes['isolate'].sum()} ({nodes['isolate'].sum()/len(nodes)*100:.1f}%)\\")\\n",
    "print(f\\"  Network Density: {nx.density(G):.4f}\\")\\n",
    "\\n",
    "print(f\\"\\\\nDemographics:\\")\\n",
    "print(f\\"  Age: {nodes['age'].mean():.1f} ± {nodes['age'].std():.1f} years\\")\\n",
    "print(f\\"  Education: {', '.join([f'{k}:{v}' for k,v in nodes['education'].value_counts().items()])}\\")\\n",
    "print(f\\"  Business Units: {len(nodes['business_unit'].unique())}\\")\\n",
    "\\n",
    "print(f\\"\\\\nNetwork Metrics (Non-Isolates):\\")\\n",
    "print(f\\"  Mean Degree: {non_isolates['degree'].mean():.2f}\\")\\n",
    "print(f\\"  Mean Log Constraint: {non_isolates['log_constraint'].mean():.3f}\\")\\n",
    "print(f\\"  Mean Betweenness: {non_isolates['betweenness'].mean():.4f}\\")\\n",
    "\\n",
    "print(f\\"\\\\nPerformance Outcomes:\\")\\n",
    "print(f\\"  Promotion Rate: {nodes['promoted_or_aboveavg'].sum()/len(nodes)*100:.1f}%\\")\\n",
    "print(f\\"  Survey Response Rate: {nodes['responded'].sum()/len(nodes)*100:.1f}%\\")\\n",
    "ideas = nodes[nodes['idea_expressed'] == True]\\n",
    "print(f\\"  Idea Expression Rate: {len(ideas)/nodes['responded'].sum()*100:.1f}% (among respondents)\\")\\n",
    "print(f\\"  Mean Idea Value: {ideas['idea_value'].mean():.2f} (scale 1-5)\\")\\n",
    "print(f\\"  Idea Dismissal Rate: {ideas['idea_dismissed'].sum()/len(ideas)*100:.1f}%\\")\\n",
    "\\n",
    "print(f\\"\\\\nNetwork Structure:\\")\\n",
    "print(f\\"  Cross-BU Ties: {((edges['bu_u'] != edges['bu_v']).sum() / len(edges) * 100):.1f}%\\")\\n",
    "print(f\\"  Tie Types: {', '.join([f'{k}:{v}' for k,v in edges['tie_type'].value_counts().items()])}\\")\\n",
    "\\n",
    "print(\\"\\\\n\\" + \\"="*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
